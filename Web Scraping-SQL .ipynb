{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    ">\n",
    "> The purpose of this notebook is to web scrape movies informations on IMDB. The data collected are : \n",
    "> - title\n",
    "> - year\n",
    "> - categroy\n",
    "> - country\n",
    "> - actor\n",
    "> - director\n",
    "> - grade\n",
    "> - length\n",
    "> - number of votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [2:42:58<00:00, 48.89s/it]\n"
     ]
    }
   ],
   "source": [
    "from time import sleep, time\n",
    "from random import randint\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "url_base = 'https://www.imdb.com/search/title/?title_type=feature&release_date=2000-01-01,2020-12-31&start='\n",
    "start = np.arange(1, 10000, 50)\n",
    "\n",
    "title = []\n",
    "year = []\n",
    "certif = []\n",
    "runtime = []\n",
    "cat = []\n",
    "grade = []\n",
    "nb_vote = []\n",
    "country = []\n",
    "language = []\n",
    "director = []\n",
    "star = []\n",
    "request = 0\n",
    "start_time =  time()\n",
    "\n",
    "for i in tqdm(start): # iterating over the pages\n",
    "    \n",
    "    url = url_base + str(i)\n",
    "    \n",
    "    #get the website\n",
    "    site  = get(url)\n",
    "    \n",
    "    #break - avoid overloading the site\n",
    "    print('\\n')\n",
    "    print(\"break...\")\n",
    "    sleep(randint(8,15))\n",
    "    print(\"finished \\n\")\n",
    "    \n",
    "    \n",
    "    #update the number of requests\n",
    "    request += 1\n",
    "    elapsed_time = time()-start_time\n",
    "    print('Request: {}; Frequency {} requests/s'.format(request, request/elapsed_time))\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    #error msg\n",
    "    if site.status_code != 200:\n",
    "        warn(\"Request: {}, Stauts code: {}\".format(request, site.status_code))\n",
    "        \n",
    "    \n",
    "    #BeautifulSoup\n",
    "    parser = BeautifulSoup(site.text, 'html.parser')\n",
    "    \n",
    "    \n",
    "    for movie in parser.find_all(class_ = \"lister-item mode-advanced\"):\n",
    "        \n",
    "        if movie.find(\"strong\") is not None and movie.find(\"span\", class_=\"certificate\") is not None:\n",
    "        \n",
    "            #title\n",
    "            title.append(movie.find(\"h3\", class_=\"lister-item-header\").find(\"a\").text )\n",
    "        \n",
    "            #year\n",
    "            if movie.find(\"span\", class_=\"lister-item-year text-muted unbold\") is not None:\n",
    "                year.append( movie.find(\"span\", class_=\"lister-item-year text-muted unbold\").text[1:-1] )\n",
    "                \n",
    "            else:\n",
    "                year.append(None)\n",
    "        \n",
    "            #certif\n",
    "            certif.append( movie.find(\"span\", class_=\"certificate\").text ) \n",
    "        \n",
    "            #length\n",
    "            if movie.find(\"span\", class_=\"runtime\") is not None:\n",
    "                runtime.append( int(movie.find(\"span\", class_=\"runtime\").text.split()[0]) )\n",
    "            \n",
    "            else:\n",
    "                runtime.append(None)\n",
    "        \n",
    "        \n",
    "            #category\n",
    "            if movie.find(\"span\", class_=\"genre\") is not None:\n",
    "                cat.append( movie.find(\"span\", class_=\"genre\").text.split(\",\")[0].split()[0] ) \n",
    "            \n",
    "            else:\n",
    "                cat.append(None)\n",
    "        \n",
    "            #grade\n",
    "            grade.append( float(movie.find(\"strong\").text) ) \n",
    "        \n",
    "            #nb of votes\n",
    "            if movie.find(\"span\", attrs = {\"name\": \"nv\"}) is not None:\n",
    "                nb_vote.append( int(movie.find(\"span\", attrs = {\"name\": \"nv\"})[\"data-value\"]) ) \n",
    "            \n",
    "            else:\n",
    "                nb_vote.append(None)\n",
    "        \n",
    "        \n",
    "            #moove to the movie's webpage\n",
    "            link_movie = \"https://www.imdb.com\" + movie.find(\"h3\", class_=\"lister-item-header\").find(\"a\")[\"href\"]\n",
    "            parser_movie = BeautifulSoup(get(link_movie).text, 'html.parser')\n",
    "        \n",
    "            #Country\n",
    "            if parser_movie.find(\"a\", href=re.compile(\"country\")) is not None:\n",
    "                country.append( parser_movie.find(\"a\", href=re.compile(\"country\")).text )\n",
    "            \n",
    "            else:\n",
    "                country.append(None)\n",
    "        \n",
    "            #Language\n",
    "            if parser_movie.find(\"a\", href=re.compile(\"language\")) is not None:\n",
    "                language.append( parser_movie.find(\"a\", href=re.compile(\"language\")).text ) \n",
    "            \n",
    "            else:\n",
    "                language.append(None)\n",
    "        \n",
    "        \n",
    "            #director and actor\n",
    "            casting = parser_movie.find_all(\"div\", class_ = \"credit_summary_item\")\n",
    "            if len(casting) == 3:\n",
    "                director.append( casting[0].a.text )\n",
    "                star.append( casting[2].a.text ) \n",
    "            \n",
    "            else:\n",
    "                director.append( casting[0].a.text )\n",
    "                star.append( casting[1].a.text ) \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the DataBase\n",
    ">\n",
    "> Once the data collected, we will create the database `imdb.db` on SQLite. It will contain 4 tables with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "connexion = sqlite3.connect(\"imdb.db\")\n",
    "connexion.execute(\"PRAGMA foreign_keys = on;\")\n",
    "c = connexion.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the tables\n",
    "> **Category** : the categories of the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\"CREATE TABLE Category(\"\n",
    "        \"id integer PRIMARY KEY,\"\n",
    "        \"category text);\"\n",
    "        )\n",
    "\n",
    "c.execute(query)\n",
    "connexion.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Film** : informations about the movies. To distinguish the categories, there is the foreign key `category_id` linked to the column `id` of the table `category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\"CREATE TABLE Film(\"\n",
    "         \"id integer PRIMARY KEY,\"\n",
    "         \"title text, \"\n",
    "         \"grade real, \"\n",
    "         \"length integer, \"\n",
    "         \"nb_vote integer,\"\n",
    "         \"language text,\"\n",
    "         \"country text,\"\n",
    "         \"category_id integer,\"\n",
    "         \"FOREIGN KEY(category_id) REFERENCES Category(id));\"\n",
    "        )\n",
    "\n",
    "c.execute(query)\n",
    "connexion.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Actor**: all the actors of the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\"CREATE TABLE Actor(\"\n",
    "        \"id integer PRIMARY KEY,\"\n",
    "        \"actor text);\"\n",
    "        )\n",
    "\n",
    "c.execute(query)\n",
    "connexion.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Director**: all the directors of the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\"CREATE TABLE Director(\"\n",
    "        \"id integer PRIMARY KEY,\"\n",
    "        \"director text);\"\n",
    "        )\n",
    "\n",
    "c.execute(query)\n",
    "connexion.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Casting**: an intermediate table to link each movie to his director (`Director`) and his actor (`Actor`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\"CREATE TABLE Casting(\"\n",
    "        \"id integer PRIMARY KEY,\"\n",
    "        \"id_title integer,\"\n",
    "        \"actor_id integer, \"\n",
    "        \"director_id integer,\"\n",
    "        \"FOREIGN KEY(id_title) REFERENCES Film(id), \"\n",
    "        \"FOREIGN KEY(actor_id) REFERENCES Actor(id),\"\n",
    "        \"FOREIGN KEY(director_id) REFERENCES Director(id));\"\n",
    "        )\n",
    "\n",
    "c.execute(query)\n",
    "connexion.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Category\n",
    "i = 0\n",
    "category2id = dict()\n",
    "for category in np.unique(cat): \n",
    "    category2id[category] = i\n",
    "    item = (i, category)\n",
    "    c.execute('INSERT INTO Category values (?,?)', item)\n",
    "    i +=1\n",
    "\n",
    "\n",
    "#Film\n",
    "i = 0\n",
    "for titre, note, duree, votes, pays, langue, category in zip(title, grade, runtime, nb_vote, country, language, cat):\n",
    "    item = (i, titre, note, duree, votes, pays, langue, category2id[category])\n",
    "    c.execute('INSERT INTO Film values (?,?,?,?,?,?,?,?)', item)\n",
    "    i +=1\n",
    "\n",
    "\n",
    "#Actor\n",
    "i = 0\n",
    "actor2id = dict()\n",
    "id2actor = dict()\n",
    "for actor in np.unique(star):\n",
    "    actor2id[actor] = i\n",
    "    id2actor[i] = actor\n",
    "    item = (i, actor)\n",
    "    c.execute('INSERT INTO Actor values (?,?)', item)\n",
    "    i +=1\n",
    "\n",
    "\n",
    "#Director\n",
    "i = 0\n",
    "director2id = dict()\n",
    "id2director = dict()\n",
    "for dire in np.unique(director):\n",
    "    director2id[dire] = i\n",
    "    id2director[i] = dire\n",
    "    item = (i, dire)\n",
    "    c.execute('INSERT INTO Director values (?,?)', item)\n",
    "    i +=1\n",
    "\n",
    "\n",
    "#Casting\n",
    "i = 0\n",
    "for titre, actor, dire in zip(title, star, director):\n",
    "    item = (i, title.index(titre), actor2id[actor], director2id[dire])\n",
    "    c.execute('INSERT INTO Casting values (?,?,?,?)', item)  \n",
    "    i +=1\n",
    "\n",
    "\n",
    "connexion.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
